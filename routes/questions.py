from fastapi import APIRouter, Request, HTTPException, status
from utils import (
    get_data_from_knowledge_base,
    get_current_user,
    get_data_from_users,
    insert_question_data,
)
from dotenv import load_dotenv
import google.generativeai as genai
import os
import json
import re


questions_routes = APIRouter()

load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
model = genai.GenerativeModel("gemini-2.5-flash")


@questions_routes.get("/Get_data_from_kb")
def Get_data_from_kb(request: Request):
    print("the data of the current user is:")
    current_usr_id = get_current_user(request)
    print(current_usr_id)
    data = get_data_from_users(current_usr_id["id"])
    return data


# this route will create the questions and the answers to it
@questions_routes.post("/create_technical")
async def create_technical(request: Request):
    # take the job profile that the user wants
    data = await request.json()
    user_job_porfile = data.get("job_profile", "software engeneer")
    current_user_id = get_current_user(request)
    resume_analysis = get_data_from_users(current_user_id["id"])
    prompt = f"""
    You are an expert technical evaluator and assessment designer.

    You will be provided with:
    1. A **job profile description**.
    2. A **detailed JSON analysis of a candidate's resume**.

    Your task:
    Generate a set of **10 multiple-choice technical questions** that evaluate both:
    - The candidate's **existing technical strengths** (from their resume analysis).
    - The **target job role's required skills** (from the provided job profile).

    ### Quiz Design Requirements:
    1. **Coverage balance:**
    - ~60% of questions should be based on the candidate‚Äôs current skills and experiences.
    - ~40% should be based on the job profile‚Äôs expected technologies or new skill areas.
    - If the resume and job role overlap heavily, evenly distribute questions across both areas.
    2. **Question composition:**
    - Each question must have **exactly 4 distinct answer options**.
    - Include **the correct answer explicitly** in a separate `"answer"` field.
    - Maintain consistent difficulty as per `"quiz_level"` from the resume analysis.
    3. **Bridge questions:**
    - Include 1‚Äì3 ‚Äúbridge‚Äù questions that connect resume skills with target job skills (e.g., Python ‚Üí Java OOP parallels).
    4. **JSON format only:**
    - Output must be valid JSON ‚Äî no markdown, no commentary, no extra text.
    5. **Metadata for each question:**
    - `"topic"`: derived from either `"final_quiz_topics"`, `"assessment_areas"`, or inferred from the job profile.
    - `"difficulty"`: equal to `"quiz_level"` from the resume analysis.
    - `"source"`: one of `"resume"`, `"job_profile"`, or `"bridge"` to indicate question origin.

    ### Inputs:
    - Job Profile: {user_job_porfile}
    - Resume Analysis JSON: {resume_analysis}

    ### Expected Output Format:
    {{
    "questions": [
        {{
        "question": "What is the role of a Dockerfile in application deployment?",
        "options": [
            "It defines environment variables only",
            "It stores source code for deployment",
            "It specifies instructions to build a Docker image",
            "It manages Docker containers at runtime"
        ],
        "answer": "It specifies instructions to build a Docker image",
        "topic": "Containerization (Docker)",
        "difficulty": "intermediate",
        "source": "resume"
        }},
        {{
        "question": "Which annotation is used to define a REST controller in Spring Boot?",
        "options": [
            "@RestController",
            "@RequestHandler",
            "@APIEndpoint",
            "@WebMapping"
        ],
        "answer": "@RestController",
        "topic": "Java Backend Fundamentals (Spring Boot)",
        "difficulty": "intermediate",
        "source": "job_profile"
        }},
        {{
        "question": "Which programming concept is common to both Python and Java OOP?",
        "options": [
            "Encapsulation",
            "Duck Typing",
            "Dynamic Typing",
            "Scripting"
        ],
        "answer": "Encapsulation",
        "topic": "OOP Concepts (Python ‚Üî Java)",
        "difficulty": "intermediate",
        "source": "bridge"
        }}
    ]
    }}
    """
    response = model.generate_content(prompt)
    question_list = response.text
    try:
        # Remove code block formatting if Gemini adds it
        cleaned_json = re.sub(r"^```json\n|\n```$", "", question_list.strip())
        # Convert string to a dict
        parsed_json = json.loads(cleaned_json)
        only_questions = parsed_json["questions"]
        print("before inserting")
        insert_question_data(
            current_user_id["id"], category="technical", questions=only_questions
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error parsing AI response: {str(e)}\nRaw response: {question_list}",
        )

    return {"questions": only_questions}


# this route will create the apptitude related questions for the user
@questions_routes.post("/create_apptitude")
def create_apptitude(request: Request):
    current_user = get_current_user(request)
    resume_analysis = get_data_from_users(current_user["id"])

    prompt = f"""
    You are an expert psychometric and aptitude test designer.

    You will be provided with:
    1. A **detailed JSON analysis** of a candidate‚Äôs resume, which includes their skill areas, experience level, and quiz difficulty level.
    2. Your task is to generate a **personalized aptitude test** that matches the user‚Äôs cognitive and professional level.

    ---

    ### üéØ Task:
    Generate **10 multiple-choice aptitude questions** that assess general intelligence, reasoning, and problem-solving abilities.

    The questions must include:
    - **5 General Aptitude Questions** ‚Äî purely logical, numerical, or verbal reasoning questions of increasing difficulty.
    - **5 Resume-Aligned Aptitude Questions** ‚Äî aptitude questions that *indirectly relate* to the candidate‚Äôs professional background or skills mentioned in the provided resume analysis (e.g., pattern recognition using code logic, data interpretation using tables, estimation involving project timelines, or verbal reasoning using technical scenarios).

    ---

    ### üß† Design Rules:

    1. **Difficulty Adaptation:**
    - The difficulty must align with the candidate‚Äôs `"quiz_level"` (e.g., beginner, intermediate, advanced).
    - If `"quiz_level"` is missing, infer it from experience or seniority in the resume analysis.
    - Difficulty progression:
        - First 3 questions ‚Üí Easy
        - Next 4 questions ‚Üí Medium
        - Last 3 questions ‚Üí Hard
    - Ensure both general and resume-aligned sets follow this progression.

    2. **Category Distribution:**
    - Logical reasoning: ~40%
    - Numerical reasoning: ~40%
    - Verbal reasoning: ~20%

    3. **Relevance & Resume Integration:**
    - For the 5 **resume-aligned** questions, create reasoning problems inspired by the user‚Äôs technical or domain background (from `resume_analysis`).
        Examples:
        - A logical flow question referencing debugging or data flow.
        - A numerical estimation question based on project timelines or performance metrics.
        - A verbal reasoning question using professional communication tone or terminology.
    - Avoid directly testing technical skills ‚Äî the focus is still aptitude.

    4. **Answer Format:**
    - Each question must have **exactly 4 distinct answer options**.
    - Include the correct answer in an `"answer"` field.
    - Add a `"source"` field with value `"general"` or `"resume_based"`.

    5. **Output Format:**
    - Output **pure JSON only** (no markdown or explanations).
    - Each question must include:
        - `"question"`
        - `"options"` (list of 4 strings)
        - `"answer"`
        - `"type"`: one of `["logical", "numerical", "verbal"]`
        - `"difficulty"`: `"easy"`, `"medium"`, or `"hard"`
        - `"source"`: `"general"` or `"resume_based"`

    ---

    ### Inputs:
    Resume Analysis JSON: {resume_analysis}

    ---

    ### Example Output:
    {{
    "questions": [
        {{
        "question": "If a train travels 120 km in 2 hours, how long will it take to travel 300 km at the same speed?",
        "options": ["3 hours", "4 hours", "5 hours", "6 hours"],
        "answer": "5 hours",
        "type": "numerical",
        "difficulty": "easy",
        "source": "general"
        }},
        {{
        "question": "A developer completes a module in 5 days. If each subsequent module takes 20% less time, how many days for the 3rd module?",
        "options": ["3.2", "3.5", "4.0", "4.5"],
        "answer": "3.2",
        "type": "numerical",
        "difficulty": "medium",
        "source": "resume_base
        }},
        {{
        "question": "Choose the grammatically correct sentence:",
        "options": [
            "Each of the files have been uploaded.",
            "Each of the files has been uploaded.",
            "Each of file has been uploaded.",
            "Each file have been uploaded."
        ],
        "answer": "Each of the files has been uploaded.",
        "type": "verbal",
        "difficulty": "easy",
        "source": "general"
        }}
    ]
    }}
    """
    response = model.generate_content(prompt)
    question_list = response.text
    try:
        # Remove code block formatting if Gemini adds it
        cleaned_json = re.sub(r"^```json\n|\n```$", "", question_list.strip())
        # Convert string to a dict
        parsed_json = json.loads(cleaned_json)
        only_questions = parsed_json["questions"]
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error parsing AI response: {str(e)}\nRaw response: {question_list}",
        )

    return {"questions": only_questions}


# this route will create the apptitude related questions for the user
@questions_routes.post("/create_communication")
def create_communication():

    prompt = f"""
    You are an expert psychometric test designer specializing in **professional communication assessment**.

    Your goal is to generate **10 multiple-choice questions** that evaluate a candidate‚Äôs ability to communicate effectively and professionally in real-world workplace contexts.

    ---

    ### üéØ Core Objective:
    Design questions that measure the candidate‚Äôs ability to convey, interpret, and adapt communication appropriately across professional scenarios such as meetings, emails, team collaborations, client interactions, and feedback discussions.

    ---

    ### üß† Skill Areas to Cover (balanced coverage required):
    1. **Clarity & Conciseness** ‚Äì Expressing ideas effectively and efficiently.
    2. **Active Listening** ‚Äì Understanding and recalling information accurately.
    3. **Written Communication** ‚Äì Grammar, tone, structure, and professionalism in written correspondence.
    4. **Verbal Communication** ‚Äì Articulation, tone, and response in spoken interactions.
    5. **Non-Verbal Interpretation** ‚Äì Recognizing and responding appropriately to body language and expressions.
    6. **Adaptability** ‚Äì Adjusting communication style to suit audience and context.
    7. **Conflict Resolution** ‚Äì Using communication to manage disagreements professionally.
    8. **Professional Etiquette** ‚Äì Appropriate use of language and tone in workplace communication.
    9. **Following Instructions** ‚Äì Accurately interpreting and executing communicated directions.
    10. **Summarization & Paraphrasing** ‚Äì Condensing or rephrasing key points effectively.

    ---

    ### üß© Question Design Rules:
    1. Each question must be based on a **realistic workplace scenario** (e.g., email exchange, team conversation, client update).
    2. Avoid grammar-only or trivia-type questions ‚Äî focus on **judgment, reasoning, and communication awareness**.
    3. Maintain varied difficulty:
    - 3 easy (basic understanding)
    - 4 medium (applied reasoning)
    - 3 hard (complex or situational)
    4. Each question must include:
    - `"question"`: The text of the question.
    - `"options"`: Exactly 4 distinct answer choices.
    - `"answer"`: The correct answer text.
    - `"skill_area"`: One of the 10 skill areas above.
    - `"difficulty"`: `"easy"`, `"medium"`, or `"hard"`.

    ---

    ### üìÑ Output Format:
    Output **only valid JSON** ‚Äî no markdown, no commentary, no explanations.

    Example:
    {{
    "questions": [
        {{
        "question": "During a team meeting, you notice a colleague repeatedly interrupts others. What is the most professional way to handle this?",
        "options": [
            "Ignore it and continue speaking",
            "Confront them directly during the meeting",
            "Wait for your turn and address it privately afterward",
            "Complain to HR immediately"
        ],
        "answer": "Wait for your turn and address it privately afterward",
        "skill_area": "Conflict Resolution",
        "difficulty": "medium"
        }},
        {{
        "question": "Which of the following best demonstrates active listening during a one-on-one conversation?",
        "options": [
            "Interrupting to share your point",
            "Maintaining eye contact and summarizing what the speaker said",
            "Taking notes silently without feedback",
            "Nodding occasionally without speaking"
        ],
        "answer": "Maintaining eye contact and summarizing what the speaker said",
        "skill_area": "Active Listening",
        "difficulty": "easy"
        }}
    ]
    }}

    Now, using this structure, generate 10 such questions **along with their correct answers**, fully formatted in pure JSON.
    """
    response = model.generate_content(prompt)
    question_list = response.text
    try:
        # Remove code block formatting if Gemini adds it
        cleaned_json = re.sub(r"^```json\n|\n```$", "", question_list.strip())
        # Convert string to a dict
        parsed_json = json.loads(cleaned_json)
        only_questions = parsed_json["questions"]
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error parsing AI response: {str(e)}\nRaw response: {question_list}",
        )

    return {"questions": only_questions}


# to write the route to create the total score of the quizes
